from networkx.algorithms.dag import descendants
from tqdm import tqdm
from keras.preprocessing.text import Tokenizer

class ApiSequenceGenerator:
    def __init__(self):
        # Inizializza il tokenizzatore di parole
        self.tokenizer = Tokenizer()

    def _tokenize(self, api_call_graph):
        # Crea la coda dei nodi da visitare
        queue = []
        # Aggiungi i nodi senza predecessori alla coda
        self._find_entrypoints(api_call_graph, queue)
        # Inizializza la lista degli ordini dei nodi
        node_order = []
        # Esegui l'ordinamento topologico
        self._follow_topology(api_call_graph, queue, node_order)
        # Costruisci la stringa di nodi
        api_call_string = self._build_sequence(node_order)
        return api_call_string

    def _find_entrypoints(self, api_call_graph, queue):
        for node in api_call_graph.nodes:
            if api_call_graph.in_degree(node) == 0:
                queue.append(node)

    def _follow_topology(self, api_call_graph, queue, node_order):
        while queue:
            # Estrai il primo nodo dalla coda
            node = queue.pop(0)
            # Aggiungi il nodo alla lista degli ordini
            node_order.append(node)
            # Aggiungi i successori del nodo alla coda
            for successor in api_call_graph.successors(node):
                queue.append(successor)

    def _build_sequence(self, node_order):
        api_call_string = ""
        for node in node_order:
            node = str(node).split(';->', 1)[1].split('(')[0]
            api_call_string += str(node) + " "
        return api_call_string

    def preprocess(self, api_call_graph):
        # Tokenizza il grafo di chiamate API
        api_call_sequence = self._tokenize(api_call_graph)
        return [api_call_sequence]
